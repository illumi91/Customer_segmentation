{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is D816-28B0\n",
      "\n",
      " Directory of C:\\Users\\luigi\\FlatironSchool\\market_segmentation\\Customer_segmentation\n",
      "\n",
      "03/05/2020  10:13    <DIR>          .\n",
      "03/05/2020  10:13    <DIR>          ..\n",
      "30/04/2020  13:54    <DIR>          .ipynb_checkpoints\n",
      "20/09/2019  22:35        45,580,638 data.csv\n",
      "30/04/2020  13:48                55 README.md\n",
      "03/05/2020  10:13            76,930 Untitled.ipynb\n",
      "               3 File(s)     45,657,623 bytes\n",
      "               3 Dir(s)   3,650,199,552 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime, nltk, warnings\n",
    "import matplotlib.cm as cm\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn import preprocessing, model_selection, metrics, feature_selection\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import neighbors, linear_model, svm, tree, ensemble\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import display, HTML\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode,iplot\n",
    "init_notebook_mode(connected=True)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "plt.style.use('fivethirtyeight')\n",
    "mpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "\n",
       "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
       "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
       "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the datafile\n",
    "df_initial = pd.read_csv('data.csv',encoding=\"ISO-8859-1\")\n",
    "df_initial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (541909, 8)\n"
     ]
    }
   ],
   "source": [
    "print('Dataframe dimensions:', df_initial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial['InvoiceDate'] = pd.to_datetime(df_initial['InvoiceDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives some infos on columns types and numer of null values\n",
    "tab_info=pd.DataFrame(df_initial.dtypes).T.rename(index={0:'column type'})\n",
    "tab_info=tab_info.append(pd.DataFrame(df_initial.isnull().sum()).T.rename(index={0:'null values (nb)'}))\n",
    "tab_info=tab_info.append(pd.DataFrame(df_initial.isnull().sum()/df_initial.shape[0]*100).T.\n",
    "                         rename(index={0:'null values (%)'}))\n",
    "display(tab_info)\n",
    "#__________________\n",
    "# show first lines\n",
    "display(df_initial[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  âˆ¼ 25% of the entries are not assigned to a particular customer. With the data available, it is impossible to impute values for the user and these entries are thus useless for the current exercise. So I delete them from the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial.dropna(axis = 0, subset = ['CustomerID'], inplace = True)\n",
    "print('Dataframe dimensions:', df_initial.shape)\n",
    "#____________________________________________________________\n",
    "# gives some infos on columns types and numer of null values\n",
    "tab_info=pd.DataFrame(df_initial.dtypes).T.rename(index={0:'column type'})\n",
    "tab_info=tab_info.append(pd.DataFrame(df_initial.isnull().sum()).T.rename(index={0:'null values (nb)'}))\n",
    "tab_info=tab_info.append(pd.DataFrame(df_initial.isnull().sum()/df_initial.shape[0]*100).T.\n",
    "                         rename(index={0:'null values (%)'}))\n",
    "display(tab_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, therefore, by removing these entries we end up with a dataframe filled at 100% for all variables! Finally, I check for duplicate entries and delete them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Duplicates: {}'.format(df_initial.duplicated().sum()))\n",
    "df_initial.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exploring the content of variables\n",
    "This dataframe contains 8 variables that correspond to:\n",
    "\n",
    "InvoiceNo: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n",
    "StockCode: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n",
    "Description: Product (item) name. Nominal.\n",
    "Quantity: The quantities of each product (item) per transaction. Numeric.\n",
    "InvoiceDate: Invice Date and time. Numeric, the day and time when each transaction was generated.\n",
    "UnitPrice: Unit price. Numeric, Product price per unit in sterling.\n",
    "CustomerID: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n",
    "Country: Country name. Nominal, the name of the country where each customer resides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_initial[['CustomerID', 'InvoiceNo', 'Country']].groupby(['CustomerID', 'InvoiceNo', 'Country']).count()\n",
    "temp = temp.reset_index(drop = False)\n",
    "countries = temp['Country'].value_counts()\n",
    "print('Nb. countries: {}'.format(len(countries) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and show the result on a chloropleth map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(type='choropleth',\n",
    "locations = countries.index,\n",
    "locationmode = 'country names', z = countries,\n",
    "text = countries.index, colorbar = {'title':'Order nb.'},\n",
    "colorscale=[[0, 'rgb(224,255,255)'],\n",
    "            [0.01, 'rgb(166,206,227)'], [0.02, 'rgb(31,120,180)'],\n",
    "            [0.03, 'rgb(178,223,138)'], [0.05, 'rgb(51,160,44)'],\n",
    "            [0.10, 'rgb(251,154,153)'], [0.20, 'rgb(255,255,0)'],\n",
    "            [1, 'rgb(227,26,28)']],    \n",
    "reversescale = False)\n",
    "#_______________________\n",
    "layout = dict(title='Number of orders per country',\n",
    "geo = dict(showframe = True, projection={'type':'mercator'}))\n",
    "#______________\n",
    "choromap = go.Figure(data = [data], layout = layout)\n",
    "iplot(choromap, validate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dataset is largely dominated by orders made from the UK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customers and products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe contains  âˆ¼ 400,000 entries. What are the number of users and products in these entries ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([{'products': len(df_initial['StockCode'].value_counts()),    \n",
    "               'transactions': len(df_initial['InvoiceNo'].value_counts()),\n",
    "               'customers': len(df_initial['CustomerID'].value_counts()),  \n",
    "              }], columns = ['products', 'transactions', 'customers'], index = ['quantity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the data concern 4372 users and that they bought 3684 different products. The total number of transactions carried out is of the order of  âˆ¼ 22'000.\n",
    "\n",
    "Now I will determine the number of products purchased in every transaction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_initial.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['InvoiceDate'].count()\n",
    "nb_products_per_basket = temp.rename(columns = {'InvoiceDate':'Number of products'})\n",
    "nb_products_per_basket[:10].sort_values('CustomerID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first lines of this list shows several things worthy of interest:\n",
    "\n",
    "- the existence of entries with the prefix C for the InvoiceNo variable: this indicates transactions that have been canceled\n",
    "- the existence of users who only came once and only purchased one product (e.g. nÂº12346)\n",
    "- the existence of frequent users that buy a large number of items at each order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Cancelling orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, I count the number of transactions corresponding to canceled orders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_products_per_basket['order_canceled'] = nb_products_per_basket['InvoiceNo'].apply(lambda x:int('C' in x))\n",
    "display(nb_products_per_basket[:5])\n",
    "#______________________________________________________________________________________________\n",
    "n1 = nb_products_per_basket['order_canceled'].sum()\n",
    "n2 = nb_products_per_basket.shape[0]\n",
    "print('Number of orders canceled: {}/{} ({:.2f}%) '.format(n1, n2, n1/n2*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the number of cancellations is quite large ( âˆ¼ 16% of the total number of transactions). Now, let's look at the first lines of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_initial.sort_values('CustomerID')[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On these few lines, we see that when an order is canceled, we have another transactions in the dataframe, mostly identical except for the Quantity and InvoiceDate variables. I decide to check if this is true for all the entries. To do this, I decide to locate the entries that indicate a negative quantity and check if there is systematically an order indicating the same quantity (but positive), with the same description (CustomerID, Description and UnitPrice):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = df_initial[df_initial['Quantity'] < 0][['CustomerID','Quantity',\n",
    "                                                   'StockCode','Description','UnitPrice']]\n",
    "for index, col in  df_check.iterrows():\n",
    "    if df_initial[(df_initial['CustomerID'] == col[0]) & (df_initial['Quantity'] == -col[1]) \n",
    "                & (df_initial['Description'] == col[2])].shape[0] == 0: \n",
    "        print(df_check.loc[index])\n",
    "        print(15*'-'+'>'+' HYPOTHESIS NOT FULFILLED')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the initial hypothesis is not fulfilled because of the existence of a 'Discount' entry. I check again the hypothesis but this time discarding the 'Discount' entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = df_initial[(df_initial['Quantity'] < 0) & (df_initial['Description'] != 'Discount')][\n",
    "                                 ['CustomerID','Quantity','StockCode',\n",
    "                                  'Description','UnitPrice']]\n",
    "\n",
    "for index, col in  df_check.iterrows():\n",
    "    if df_initial[(df_initial['CustomerID'] == col[0]) & (df_initial['Quantity'] == -col[1]) \n",
    "                & (df_initial['Description'] == col[2])].shape[0] == 0: \n",
    "        print(index, df_check.loc[index])\n",
    "        print(15*'-'+'>'+' HYPOTHESIS NOT FULFILLED')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once more, we find that the initial hypothesis is not verified. Hence, cancellations do not necessarily correspond to orders that would have been made beforehand.\n",
    "\n",
    "At this point, I decide to create a new variable in the dataframe that indicate if part of the command has been canceled. For the cancellations without counterparts, a few of them are probably due to the fact that the buy orders were performed before December 2010 (the point of entry of the database). Below, I make a census of the cancel orders and check for the existence of counterparts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
